{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation English to German Audio Experiment\n",
    "## Experiment 4\n",
    "### Text Translation & TTS 1\n",
    "\n",
    "https://huggingface.co/blog/speecht5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text To Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "Albert Einstein ( 14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely acknowledged to be one of the greatest physicists of all time. \n",
    "Einstein is best known for developing the theory of relativity, but he also made important contributions to the development of the theory of quantum mechanics. \n",
    "Relativity and quantum mechanics are together the two pillars of modern physics.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_model_and_tokenizer(src_lang, dst_lang):\n",
    "  \"\"\"\n",
    "  Given the source and destination languages, returns the appropriate model\n",
    "  See the language codes here: https://developers.google.com/admin-sdk/directory/v1/languages\n",
    "  For the 3-character language codes, you can google for the code!\n",
    "  \"\"\"\n",
    "  # construct our model name\n",
    "  model_name = f\"Helsinki-NLP/opus-mt-{src}-{dst}\"\n",
    "  # initialize the tokenizer & model\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "  # return them for use\n",
    "  return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading file source.spm from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\source.spm\n",
      "loading file target.spm from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\target.spm\n",
      "loading file vocab.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\vocab.json\n",
      "loading file target_vocab.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\tokenizer_config.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 58100\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-de.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-de\\snapshots\\6183067f769a302e3861815543b9f312c71b0ca4\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"renormalize_logits\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# source & destination languages\n",
    "src = \"en\"\n",
    "dst = \"de\"\n",
    "\n",
    "model, tokenizer = get_translation_model_and_tokenizer(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7799, 39858,    20,   536,  1290,   268,  3977,   112,   268,   757,\n",
      "         18170,    27,    58,    14,   586,    13,  4904, 15823, 38818,     2,\n",
      "         10884, 20420,    12,    43,   128,     7,     4,  7833, 38818,     6,\n",
      "             7,    92,   160,     3, 39858,    19,   517,  1369,    23,  3121,\n",
      "             4,  8807,     7,  5049,   658,     2,   144,   137,   115,   319,\n",
      "           501,  6820,    12,     4,   478,     7,     4,  8807,     7, 35266,\n",
      "         35330,     3,   465,  1270, 24370,     8, 35266, 35330,    48,   848,\n",
      "             4,   254, 26364,     7,  1457, 19419,   221,     0]])\n"
     ]
    }
   ],
   "source": [
    "# encode the text into tensor of integers using the appropriate tokenizer\n",
    "inputs = tokenizer.encode(article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Outputs\n",
      "Albert Einstein (14. März 1879 – 18. April 1955) war ein in Deutschland geborener theoretischer Physiker, der weithin als einer der größten Physiker aller Zeiten anerkannt wurde. Einstein ist am besten für die Entwicklung der Relativitätstheorie bekannt, leistete aber auch wichtige Beiträge zur Entwicklung der Quantenmechanik. Relativität und Quantenmechanik sind zusammen die beiden Säulen der modernen Physik.\"\n"
     ]
    }
   ],
   "source": [
    "# generate the translation output using beam search\n",
    "beam_outputs = model.generate(inputs, num_beams=3)\n",
    "# decode the output and ignore special tokens\n",
    "print(\"Beam Outputs\")\n",
    "translated_text = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(translated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup TTS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\preprocessor_config.json\n",
      "Feature extractor SpeechT5FeatureExtractor {\n",
      "  \"do_normalize\": false,\n",
      "  \"feature_extractor_type\": \"SpeechT5FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"fmax\": 7600,\n",
      "  \"fmin\": 80,\n",
      "  \"frame_signal_scale\": 1.0,\n",
      "  \"hop_length\": 16,\n",
      "  \"mel_floor\": 1e-10,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"SpeechT5Processor\",\n",
      "  \"reduction_factor\": 2,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000,\n",
      "  \"win_function\": \"hann_window\",\n",
      "  \"win_length\": 64\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm_char.model from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\spm_char.model\n",
      "loading file added_tokens.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\config.json\n",
      "Model config SpeechT5Config {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"SpeechT5ForTextToSpeech\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"encoder_max_relative_position\": 160,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"guided_attention_loss_num_heads\": 2,\n",
      "  \"guided_attention_loss_scale\": 10.0,\n",
      "  \"guided_attention_loss_sigma\": 0.4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 1876,\n",
      "  \"max_speech_positions\": 1876,\n",
      "  \"max_text_positions\": 600,\n",
      "  \"model_type\": \"speecht5\",\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"positional_dropout\": 0.1,\n",
      "  \"reduction_factor\": 2,\n",
      "  \"scale_embedding\": false,\n",
      "  \"speaker_embedding_dim\": 512,\n",
      "  \"speech_decoder_postnet_dropout\": 0.5,\n",
      "  \"speech_decoder_postnet_kernel\": 5,\n",
      "  \"speech_decoder_postnet_layers\": 5,\n",
      "  \"speech_decoder_postnet_units\": 256,\n",
      "  \"speech_decoder_prenet_dropout\": 0.5,\n",
      "  \"speech_decoder_prenet_layers\": 2,\n",
      "  \"speech_decoder_prenet_units\": 256,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_guided_attention_loss\": true,\n",
      "  \"vocab_size\": 81\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 1876,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing SpeechT5ForTextToSpeech.\n",
      "\n",
      "All the weights of SpeechT5ForTextToSpeech were initialized from the model checkpoint at microsoft/speecht5_tts.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SpeechT5ForTextToSpeech for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "tts_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenise Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_inputs = tts_processor(text=translated_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Spectogram Speech Generation Voice Vocoding and writing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan\\snapshots\\bb6f429406e86a9992357a972c0698b22043307d\\config.json\n",
      "Model config SpeechT5HifiGanConfig {\n",
      "  \"architectures\": [\n",
      "    \"SpeechT5HifiGan\"\n",
      "  ],\n",
      "  \"initializer_range\": 0.01,\n",
      "  \"leaky_relu_slope\": 0.1,\n",
      "  \"model_in_dim\": 80,\n",
      "  \"model_type\": \"hifigan\",\n",
      "  \"normalize_before\": true,\n",
      "  \"resblock_dilation_sizes\": [\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ]\n",
      "  ],\n",
      "  \"resblock_kernel_sizes\": [\n",
      "    3,\n",
      "    7,\n",
      "    11\n",
      "  ],\n",
      "  \"sampling_rate\": 16000,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"upsample_initial_channel\": 512,\n",
      "  \"upsample_kernel_sizes\": [\n",
      "    8,\n",
      "    8,\n",
      "    8,\n",
      "    8\n",
      "  ],\n",
      "  \"upsample_rates\": [\n",
      "    4,\n",
      "    4,\n",
      "    4,\n",
      "    4\n",
      "  ]\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan\\snapshots\\bb6f429406e86a9992357a972c0698b22043307d\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing SpeechT5HifiGan.\n",
      "\n",
      "All the weights of SpeechT5HifiGan were initialized from the model checkpoint at microsoft/speecht5_hifigan.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SpeechT5HifiGan for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "spectrogram = tts_model.generate_speech(tts_inputs[\"input_ids\"], speaker_embeddings)\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "speech = tts_model.generate_speech(tts_inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "sf.write(\"tts_example.wav\", speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Connor\\Desktop\\College\\FYP\\HuggingTest\\fyp-trans-tts\\experiment4.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Connor/Desktop/College/FYP/HuggingTest/fyp-trans-tts/experiment4.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Connor/Desktop/College/FYP/HuggingTest/fyp-trans-tts/experiment4.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m wavfile\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Connor/Desktop/College/FYP/HuggingTest/fyp-trans-tts/experiment4.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load the WAV file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Connor/Desktop/College/FYP/HuggingTest/fyp-trans-tts/experiment4.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sample_rate, data \u001b[39m=\u001b[39m wavfile\u001b[39m.\u001b[39mread(\u001b[39m\"\u001b[39m\u001b[39mtts_example.wav\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Replace 'path/to/file.wav' with the path to your WAV file\n",
    "Audio(filename='tts_example.wav', autoplay=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
