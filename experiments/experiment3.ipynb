{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation English to German Audio Experiment\n",
    "## Experiment 3\n",
    "### TTS 1\n",
    "\n",
    "https://huggingface.co/blog/speecht5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Connor\\Tools\\envs\\hugFace\\lib\\site-packages\\transformers\\deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Connor\\Tools\\envs\\hugFace\\lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Connor\\Tools\\envs\\hugFace\\lib\\site-packages\\transformers\\generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\preprocessor_config.json\n",
      "Feature extractor SpeechT5FeatureExtractor {\n",
      "  \"do_normalize\": false,\n",
      "  \"feature_extractor_type\": \"SpeechT5FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"fmax\": 7600,\n",
      "  \"fmin\": 80,\n",
      "  \"frame_signal_scale\": 1.0,\n",
      "  \"hop_length\": 16,\n",
      "  \"mel_floor\": 1e-10,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"SpeechT5Processor\",\n",
      "  \"reduction_factor\": 2,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000,\n",
      "  \"win_function\": \"hann_window\",\n",
      "  \"win_length\": 64\n",
      "}\n",
      "\n",
      "loading file spm_char.model from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\spm_char.model\n",
      "loading file added_tokens.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\config.json\n",
      "Model config SpeechT5Config {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"SpeechT5ForTextToSpeech\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.1,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.1,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"encoder_max_relative_position\": 160,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"guided_attention_loss_num_heads\": 2,\n",
      "  \"guided_attention_loss_scale\": 10.0,\n",
      "  \"guided_attention_loss_sigma\": 0.4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 1876,\n",
      "  \"max_speech_positions\": 1876,\n",
      "  \"max_text_positions\": 600,\n",
      "  \"model_type\": \"speecht5\",\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"positional_dropout\": 0.1,\n",
      "  \"reduction_factor\": 2,\n",
      "  \"scale_embedding\": false,\n",
      "  \"speaker_embedding_dim\": 512,\n",
      "  \"speech_decoder_postnet_dropout\": 0.5,\n",
      "  \"speech_decoder_postnet_kernel\": 5,\n",
      "  \"speech_decoder_postnet_layers\": 5,\n",
      "  \"speech_decoder_postnet_units\": 256,\n",
      "  \"speech_decoder_prenet_dropout\": 0.5,\n",
      "  \"speech_decoder_prenet_layers\": 2,\n",
      "  \"speech_decoder_prenet_units\": 256,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_guided_attention_loss\": true,\n",
      "  \"vocab_size\": 81\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_tts\\snapshots\\e98d26ca6f846470cf3f6086f64e6a2cbb096943\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 1876,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing SpeechT5ForTextToSpeech.\n",
      "\n",
      "All the weights of SpeechT5ForTextToSpeech were initialized from the model checkpoint at microsoft/speecht5_tts.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SpeechT5ForTextToSpeech for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenise Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=\"Don't count the days, make the days count.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Spectogram Speech Generation Voice Vocoding and writing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eff4ad778543bca7b578b1cb912b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Connor\\Tools\\envs\\hugFace\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Connor\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "loading configuration file config.json from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan\\snapshots\\bb6f429406e86a9992357a972c0698b22043307d\\config.json\n",
      "Model config SpeechT5HifiGanConfig {\n",
      "  \"architectures\": [\n",
      "    \"SpeechT5HifiGan\"\n",
      "  ],\n",
      "  \"initializer_range\": 0.01,\n",
      "  \"leaky_relu_slope\": 0.1,\n",
      "  \"model_in_dim\": 80,\n",
      "  \"model_type\": \"hifigan\",\n",
      "  \"normalize_before\": true,\n",
      "  \"resblock_dilation_sizes\": [\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      3,\n",
      "      5\n",
      "    ]\n",
      "  ],\n",
      "  \"resblock_kernel_sizes\": [\n",
      "    3,\n",
      "    7,\n",
      "    11\n",
      "  ],\n",
      "  \"sampling_rate\": 16000,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"upsample_initial_channel\": 512,\n",
      "  \"upsample_kernel_sizes\": [\n",
      "    8,\n",
      "    8,\n",
      "    8,\n",
      "    8\n",
      "  ],\n",
      "  \"upsample_rates\": [\n",
      "    4,\n",
      "    4,\n",
      "    4,\n",
      "    4\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0bf48baef549b4abdb2f1fdbb54624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/50.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Connor/.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan\\snapshots\\bb6f429406e86a9992357a972c0698b22043307d\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing SpeechT5HifiGan.\n",
      "\n",
      "All the weights of SpeechT5HifiGan were initialized from the model checkpoint at microsoft/speecht5_hifigan.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SpeechT5HifiGan for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "sf.write(\"tts_example.wav\", speech.numpy(), samplerate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
